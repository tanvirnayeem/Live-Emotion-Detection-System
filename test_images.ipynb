{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/macbook/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /Users/macbook/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\nWARNING:tensorflow:From /Users/macbook/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\n"
    }
   ],
   "source": [
    "name_model = './Modelos/model_dropout.hdf5'\n",
    "model = load_model(name_model)\n",
    "w,h = (48,48)\n",
    "rgb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(face_image,rgb=True,w=48,h=48):\n",
    "    face_image = cv2.resize(face_image, (w,h))\n",
    "    if rgb == False:\n",
    "        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
    "    face_image = face_image.astype(\"float\") / 255.0\n",
    "    face_image= img_to_array(face_image)\n",
    "    face_image = np.expand_dims(face_image, axis=0)\n",
    "    return face_image\n",
    "\n",
    "def bounding_box(img,box,match_name):\n",
    "    for i in np.arange(len(box)):\n",
    "        y0,x1,y1,x0 = box[i]\n",
    "        img = cv2.rectangle(img,\n",
    "                      (x0,y0),\n",
    "                      (x1,y1),\n",
    "                      (0,255,0),3);\n",
    "        cv2.putText(img, match_name, (x0, y0-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'preprocess_img' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2cd64ef33d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mface_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# preprocesar data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mface_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# predecir imagen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_img' is not defined"
     ]
    }
   ],
   "source": [
    "#ingestar data\n",
    "im = cv2.imread('data_test/friends1.jpg')\n",
    "# detectar_rostro\n",
    "box = face_recognition.face_locations(im)\n",
    "x0,y1,x1,y0 = box[0]\n",
    "face_image = im[x0:x1,y0:y1]\n",
    "# preprocesar data\n",
    "face_image = preprocess_img(face_image,rgb,w,h)\n",
    "# predecir imagen\n",
    "prediction = model.predict(face_image)[0]\n",
    "emotion = labels[prediction.argmax()]\n",
    "# visualizacion\n",
    "img_post = bounding_box(im,box,emotion)\n",
    "cv2.imshow('emotion_detection',img_post)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitocrenvvenv7fc674b1f8e54976842dc743de18c731",
   "display_name": "Python 3.7.6 64-bit ('ocr-env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}